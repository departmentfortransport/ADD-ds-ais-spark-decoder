package uk.gov.dft.ais.decode

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.udf

import utils.{extractInt, parseIntWScale, stringLength, extractString}

object decode24 {
  /**
   * Decode type 24 messages
   * params 0 - read bucket location
   * params 1 - write bucket location (parquet file)
   */
  def main (args:Array[String]): Unit = {

    // Start a spark context
    val spark = SparkSession
      .builder()
      .appName("AIS-decode-24")
      .master("yarn")
      .config("spark.executor.cores", "2")
      .config("spark.executor.memory", "1g")
      .config("spark.default.parallelism", "36500")
      .config("spark.sql.shuffle.partitions", "36500")
      .getOrCreate()

    // this import has to go after val spark.
    import spark.implicits._

    // Read in the parquet files from first argument location
    val binary_decoded_messages = spark
      .read.format("parquet")
      .load(args(0))

    val msg_24_raw = binary_decoded_messages
      // Filter just messages 24
      // this should be fast as data is partitioned my id
      .where($"id" === 24)
      // Only keep valid string lengths
      .where(
        stringLength($"dataBinary") === 168 ||
        stringLength($"dataBinary") === 162
      )

    // The section below defines user defined functions to extract data from
    // the binary string generated by rawdecode
    val getRepeat = udf [Option[Int], String] (x => extractInt(x,6,8))

    val getMMSI = udf [Option[Int] , String] (x=> extractInt(x,8,38))

    val getPartNumber = udf [Option[Int] , String] {
      // If 0, the rest of the message is Part A
      // if 1, the rest of the message is Part B
      x=> extractInt(x,38,40)
      }

    // Notes:
    //    From this point on the message might be type A or B. They are
    //    broadcast together, but may not be together in our DB. So we need
    //    to decode, match them up, then output them together. Because of this
    //    this is proably going to invovle some shuffling.

    // For each UDF run it on the dataset.
    val add_part_number = msg_24_raw
      .withColumn("decoded_repeate", getRepeat(msg_24_raw("dataBinary")))
      .withColumn("decoded_mmsi", getMMSI(msg_24_raw("dataBinary")))
      .withColumn("part_number", getPartNumber(msg_24_raw("dataBinary")))

    // Separate out the message by parts.
    // Part A only contains ship name, so these can be merged onto the info in
    // Part B later
    val part_a = add_part_number.where($"part_number"===0)
    val part_b = add_part_number
      .where($"part_number"===1 ||
        // Following libais some devides report part A as part B,
        // but the bit length gives it away
        $"part_number"===0 && stringLength($"dataBinary") === 162)

    // Part A - Message can be 168 bits, but the last 8 are not used.
    val getShipName = udf [Option[String] , String] { x=>
        extractString(x, 40, 160)
      }

    val part_a_decoded = part_a
      .withColumn("ship_name", getShipName(part_a("dataBinary")))

    // Part B
    val getShipType = udf [Option[Int] , String] ( x=> extractInt(x,40,48))

    val getVendorID = udf [Option[String] , String] { x=>
      // Vendor ID is 3 6bit characters
      extractString(x, 48, 66)
    }

    val getUnitModel = udf [Option[Int] , String] (x=> extractInt(x,66,70))

    val getSerielNumber = udf [Option[Int] , String] (x=> extractInt(x,70,90))

    val getCallSign = udf [Option[String] , String] { x=>
      extractString(x, 90,132)
    }

    val getToBow = udf [Option[Int] , String] ( x=> extractInt(x,132,141))

    val getToStern = udf [Option[Int] , String] ( x=> extractInt(x,141,150))

    val getToPort = udf [Option[Int] , String] ( x=> extractInt(x,150,156))

    val getToStarboard = udf [Option[Int] , String] ( x=> extractInt(x,156,162))

    val getMothershipMMSI = udf [Option[Int] , String] {
      x=> extractInt(x,132,162)
      }

    // Bits 162-167 are not used ('spare')


    // Process the part b messages
    val part_b_decoded = part_b
      .withColumn("ship_type", getShipType(part_b("dataBinary")))
      .withColumn("vendor_id", getVendorID(part_b("dataBinary")))
      .withColumn("unit_model", getUnitModel(part_b("dataBinary")))
      .withColumn("serial_number", getSerielNumber(part_b("dataBinary")))
      .withColumn("call_sign", getCallSign(part_b("dataBinary")))
      .withColumn("to_bow", getToBow(part_b("dataBinary")))
      .withColumn("to_stern", getToStern(part_b("dataBinary")))
      .withColumn("to_port", getToPort(part_b("dataBinary")))
      .withColumn("to_starboard", getToStarboard(part_b("dataBinary")))
      .withColumn("mothership_mmsi", getMothershipMMSI(part_b("dataBinary")))

    // Each ship can only have one name per mssi and timestamp, so reduce the
    // data set to distinct
    val part_a_subset = part_a_decoded
      .select("ship_name", "decoded_mmsi", "timestamp")
      .distinct

    // Add part a, where available to the part b
    val joined_up = part_b_decoded.join(part_a_subset,
      usingColumns = Seq("decoded_MMSI", "timestamp"),
      joinType = "left"
      )

    // write out to parquet files, location specified in the second argument
    joined_up.write.parquet(args(1))

  }
}
