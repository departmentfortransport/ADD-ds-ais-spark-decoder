package uk.gov.dft.ais.decode

import org.apache.spark.sql.{SparkSession}
import org.apache.spark.sql.functions.udf
import org.apache.spark.sql.functions.{min, max}
import scala.math.{abs, pow}
import uk.gov.dft.ais.decode.utils.{extractInt, extractString, parseIntWScale,
  stringLength}

// add the dependency
// %addJar file:///Users/willbowditch/projects/ds-ais/decode/aisdecode/target/scala-2.11/aisdecode_2.11-0.1.0.jar

object decode18{
  /**
   * Decode type 5 messages
   * params 0 - read bucket location
   * parms 1 - write bucket location (parquet file)
   */
  def main (args:Array[String]): Unit = {

    // Start a spark context
    val spark = SparkSession
      .builder()
      .appName("AIS-decode-18")
      .master("yarn")
      .config("spark.executor.cores", "2")
      .config("spark.executor.memory", "1g")
      .config("spark.default.parallelism", "36500")
      .config("spark.sql.shuffle.partitions", "36500")
      .getOrCreate()

    // this import has to go after val spark.
    import spark.implicits._

    // Read in the parquet files from first argument location
    val binary_decoded_messages = spark
      .read.format("parquet")
      .load(args(0))


    // Filter just messages 1-3
    // this should be fast as data is partitioned my id
    val msg_18_raw = binary_decoded_messages
      .where($"id" === 18)
      // Messages should be 168 bits
      .where(stringLength($"dataBinary") === 168)


    // The section below defines user defined functions to extract data from
    // the binary string generated by rawdecode
    val getRepeat = udf [Option[Int], String] (x => extractInt(x,6,8))

    val getMMSI = udf [Option[Int] , String] (x=> extractInt(x,8,38))

    // 38-46 "Regional Reserved" and not used (https://bit.ly/2CQDyoY)

    val getSOG = udf [Option[Double] , String] {x=>
      // Speed over ground is in 0.1-knot resolution from 0 to 102 knots.
      // Value 1023 indicates speed is not available
      // value 1022 indicates 102.2 knots or higher.
      extractInt(x,46,56) match {
        // If we have some scale by factor, unless 1023, then none!
        case Some(i) => if(i == 1023){None}else{Some(i / 10.0)}
        case None => None
      }
    }

    val getPositionAccuracy = udf [Option[Int] , String] {x=>
      extractInt(x,56,57)
    }

    val getLongitude = udf [Option[Double] , String] {x=>
      // Longitude is given in in 1/10000 min; divide by 600000.0 to obtain
      // degrees. Values up to plus or minus 180 degrees, East = positive,
      // West \= negative. A value of 181 degrees (0x6791AC0 hex) indicates
      // that longitude is not available and is the default.
      parseIntWScale(x.slice(57,85)) match {
        case Some(i) => {
          val long = i / 600000.0
          if (long == 181){None}else{Some(long)}
        }
        case None => None
      }
    }

    val getLatitude = udf [Option[Double] , String] {x=>
      // Latitude is given in in 1/10000 min; divide by 600000.0 to obtain
      // degrees. Values up to plus or minus 90 degrees, North = positive,
      // South = negative. A value of 91 degrees (0x3412140 hex)
      // indicates latitude is not available and is the default.
      parseIntWScale(x.slice(85,112)) match {
        case Some(i) => {
          val long = i / 600000.0
          if (long == 91){None}else{Some(long)}
        }
        case None => None
      }
    }


    val getHDG = udf [Option[Int] , String] {x=>
      // 0 to 359 degrees, 511 = not available.
      extractInt(x,124,133) match {
        case Some(i) => if(i==511){None}else{Some(i)}
        case None => None
      }
    }


    val getTimestamp = udf [Option[Int] , String] {x=>
      // Seconds in UTC timestamp should be 0-59, except for these special values:
      //  60 if time stamp is not available (default)
      //  61 if positioning system is in manual input mode
      //  62 if Electronic Position Fixing System operates in estimated (dead reckoning) mode,
      //  63 if the positioning system is inoperative.
      extractInt(x,133,139) match {
        case Some(i) => if(i > 59){None}else{Some(i)}
        case None => None
      }
    }

    // 139-140 Regional reserved (unused)

    // 0=Class B SOTDMA unit 1=Class B CS (Carrier Sense) unit
    val getCS = udf [Option[Int] , String] (x=> extractInt(x,141,142))

    // 0=No visual display, 1=Has display, (Probably not reliable).
    val getDisplayFlag = udf [Option[Int] , String] (x=> extractInt(x,142,143))

    // If 1, unit is attached to a VHF voice radio with DSC capability.
    val getDSC = udf [Option[Int] , String] (x=> extractInt(x,143,144))

    // Base stations can command units to switch frequency.
    // If this flag is 1, the unit can use any part of the marine channel.
    val getBand = udf [Option[Int] , String] (x=> extractInt(x,144,145))

    // If 1, unit can accept a channel assignment via Message Type 22.
    val getMsg22 = udf [Option[Int] , String] (x=> extractInt(x,145,146))

    // Assigned-mode flag: 0 = autonomous mode (default), 1 = assigned mode.
    val getAssigned = udf [Option[Int] , String] (x=> extractInt(x,146,147))

    val getRAIM = udf [Option[Int] , String] (x=> extractInt(x,147,148))

    // This one contains diagnostic info for radio systems, so not processing.
    val getRadioStatus = udf [Option[Int] , String] (x=> extractInt(x,149,168))

    // For each UDF run it on the dataset.
    val processed = msg_18_raw
      .withColumn("decoded_repeat",
        getRepeat(msg_18_raw("dataBinary")))
      .withColumn("decoded_mmsi",
        getMMSI(msg_18_raw("dataBinary")))
      .withColumn("speed_over_ground",
        getSOG(msg_18_raw("dataBinary")))
      .withColumn("position_accuracy",
        getPositionAccuracy(msg_18_raw("dataBinary")))
      .withColumn("longitude",
        getLongitude(msg_18_raw("dataBinary")))
      .withColumn("latitude",
        getLatitude(msg_18_raw("dataBinary")))
      .withColumn("true_heading",
        getHDG(msg_18_raw("dataBinary")))
      .withColumn("timestamp_seconds",
        getTimestamp(msg_18_raw("dataBinary")))
      .withColumn("cs_unit",
        getCS(msg_18_raw("dataBinary")))
      .withColumn("dsc_flag",
        getDSC(msg_18_raw("dataBinary")))
      .withColumn("display_flag",
        getDisplayFlag(msg_18_raw("dataBinary")))
      .withColumn("band_flag",
        getBand(msg_18_raw("dataBinary")))
      .withColumn("message_22_flag",
        getMsg22(msg_18_raw("dataBinary")))
      .withColumn("assigned",
        getAssigned(msg_18_raw("dataBinary")))
      .withColumn("raim",
        getRAIM(msg_18_raw("dataBinary")))

    // write out to parquet files, location specified in the second argument
    processed.write.parquet(args(1))
  }
}
